S3 - Simple Storage Service
	Object Storage - S3 provides secure, durable, highly-scalable object storage.
	Simple - Amazon S3 is easy to use, with a simple to use with a simple web interface.
	Scalable - S3 allows you to store and retrive any amount of data from anywhere on the web at a very low cost.
--------------------------------
S3 - is object-based  storage
	Manages data as object rather than in a file systems or data blocks.
		Upload any file type you can think of, to S3.
		Example : photos, videos, code, documents, text files
		It cannot be used to run an operating system or database
-------------------------------
Unlimited Storage
	The total volume of data and the number of objects you can store is unlimited.
Objects up to 5 TB in size
	S3 objects can range in size from a minimum of 0 bytes to a maximum of 5TB
S3 Buckets 
	Store files in buckets (similar to folders)
-------------------------------
Working with S3 Buckets
	Universal namespace
		ALl AWS accounts share the S3 namespace. Each S3 bucket name is globallyunique.
	Example S3 URLs
		https://"bucket-name".s3.Region,amazonaws.com/key-name
	Uploading files
		When you upload a file to an S3 bucket, you will receive an HTTP 200 code if the upload was successful
-------------------------------
S3 is a key-balue Store
	Key - The name of the object, for exampleL File.jpg
	Value - This is the data itself, which is made up of a sequence of bytes
	Version ID - Important for storing multiple versions of same object
	Metadata - Data about the data you are storing, e.g. content-type, last-modified, etc.
------------------------------
Safe Place
	S3 is a safe place to store your files. The data is spread across multiple devices and fasilities to ensure availability and durability.
------------------------------
S3 Highly Available and Highly Durable 
	Built for Availability - Built for 99.95% - 99.99% service availability depending on the S3 tier.
	Designed for Durability - Designed for 99.999999999% (11 9's) durability for data stored in S3.
------------------------------
S3 Characteristics
	Tiered Storage - S3 offers a range of storage classes designed for different use cases
	Lifecycle Management - Define rules to automatically transition objects to a cheaper storage tier 
		or delete objects that are no longer required after a set period of time
	Versioning - With versioning, all versions of an object are stored and can be retrived, including deleted objects.
-------------------------------
Secure your Data
	Server-Side Encryption -  you can set default encryption on a bucket to encrypt all new objects when they are stored in the bucket.
	Access Control List (ACLs) - Define which AWS accounts are granted access and the typ eof access. You can attach S3 ACL's to individual objects in bucket
	Bucket Policies - S3 bucket policies specify what actions are allowed or denied (e,g, allow user Alice to PUT but not DELETE objects in the bucket).
-------------------------------
Exam Tips:
	Object-based - Object-based allows you to upload files
	Not OS or DB Storage - Not suitable to install an operating system or run a database on.
	Files upto 5TB - files can be from 1 bytes to 5TB
	Unlimited Storage - The total volume of data and the number of objects you can store is unlimited.
------------------------------
Files Stored in Buclet 
	S3 is a universal namespace.
		https://<bucket-name>.S3.Region.amazonaws.com/key-name
	Successful CLI or API uploads will generate an HTTP 200 status code.
------------------------------
S3 Object Exam Tips
	Key - The object name, e.g. Ralphie.jpg
	Value - This is the data itself, which is made up of a sequence of bytes
	Version ID - Allows you to store multiple versions of the same object.
	Metadate - Data about the data you storing e.g. content-type, last-modified, etc.
================================
Reviewing S3 Storage Classes
	S3 Standard
	S3 Standard-Infrequent access
	S3 OneZone-infrequent Access
	S3 Glacier and S3 Glacier Deep Archive
	Intelligent-Tiering
	Relative Coast
	Exam Tips
---------------------------------
S3 Stabdard
	 High Availability and Durability 
		Data is stored redundantly across multiple devices in multiple facilities(>- 3AZ's):
			99.99% Availability
			99,999999999 Durability (11 9's)
	Designed for frequently access
		Perfectly for frequently accessed data
	Suitable for Most Workloads
		The default storage class
		Use cases include websites, content distribution, mobile and gaming applications, and big data analytics
--------------------------------
S3 Standard-Infrequent Access (S3-IA) - designed for infrequently accessed data.
	Rapid access
		Used for data that is accessed less frequently but requires rapid access when needed.
	You pay to access the Data	
		There is a low per-GB atorage price and a per-GB retrival fee.
	Use Cases
		Great for long-term storage, backuos, and disaster recovery files. Minimum storage duration: 30 days.
--------------------------------
S3 One zone-infrequent access
	Like S3-IA, but data is stored redundantly within a single AZ.
		Costs 20% less than regular s3 IA
		Great for long-lived, infrequently accessed, non-critical data
		Minimum storage duration: 30 days.

		99.5% Availability
		99.999999999% (11 9's) Durability
-------------------------------
S3 Glacier
	Glacier is a very cheap ctorage
	Optimized for data that is very infrequently accessed
	You pay each time you access your data
	Use only for archiving data

    3 Glacier Options
	S3 Glacier Instant Retrival - for archive data that needs immidiate access
	S3 Glacier Flexible Retrival (Formarly S3 Glacier) - for archive data that does not require immidiate access 
		but needs the flexirility to retrive large sets of data at no cost. retribe 1min-12H few times a year (90 days minimum)
	S3 Glacier Deep Archive for long-lived archive use cases at the lowest cost. retrive 12H, accessed 1-2 times a year (180 days minimum)

	99.99% Availability
	99.999999999% (11 9's) Durability
------------------------------
S3 - Intelligent Tiering  
	Automatically moves your data to the most cost-effective tier based on how frequently you access each object.
	2 tiers: Frequent and infrequent access
------------------------------
Securing S3 Bucket
	S3 is very secured by default
		Private - by default all newly created buckets are private
		Bucket Owner - by default, only the bucket owner can upload new files, read files, delete files, etc.
		No Public Access - no public access by default
------------------------------
Bucket Policies - you can set upaccess control to your buckets using Bucket Policies
	Applied at Bucket Level - The permissions granted by the policy apply to all of the objects within the bucket
	Not Individual Objects - you can't attach a bucket policy to an individual object.
	Groups of files - A group of files which need to be accessed by the same people
------------------------------
Bucket Policies are Written in JSON
	JS object notation language. A list of key-value pairs
	AWS provides a policy generator tool.
	To build out the policies that you need
-----------------------------
S3 Bucket Access Control List (Bucket ACLs)
	Access Control Lists - Applied at an object level. We can apply different permissions for different objects within a bucket
	Frant Access to Object - We can define which account or groups are granted access and also the type of access, e.g. read, write, or full control.
	Fine Franted Control - Grant a different type of access to different objects within the same bucket e.g. to apply different permissions
				for different objects, for different users and groups
----------------------------
S3 Access Logs
	Log all requests made to the S3 bucket. 
		e.g. Eevry time a user makes a request to upload a file, read a file, or delete a file.
		Logs written into another S3 bucket
---------------------------
Exam Tips:
	Security By Default - By default, all newly created buckets are private
	Access Logs - S3 buckets can be configured to create access logs, which log all requests made to S3 bucket. These logs can be written to another bucket.
	Control Access to Buckets: 
		- Bucket Policies - applied at a bucket level. 
		- Access Control Lists - Applied at an object level.
================================
S3 Encryption
	Why encrypt
	S3 Encryption Options
	Exam tips
-------------------------------
Why Encrypt?
	A Security Bast Practice - Protecting data using encryption is a security best practice
	Data is an Asset - All businesses store data that should be protected (e.g. financial data, customer data, business plans, proprietary code)
	Encryption - Helps protect your data against unauthorized access.
-------------------------------
S3 Encryption Options
	1. Encryption in transit
		SSL/TLS
		HTTPS
	2. Encryption at rest: server side encryption
		SSE-S3 - S3-managed keys, using AES 256 bit encryption
		SSE-KMS - AWS Key Management Service-managed keys
		SSE-C - Customer-provided keys
	3. Encryption at rest - Client side Encryption
		You encrypt the files yourself before you upload them into S3
==============================
CORS CONFIGURATION
	1. configure 2 S3 buckets - One will host index.html, and one will host loadpage.html
	2. Update the index.html file - to reference the loadpage.html stored in the other bucket.
	3. Test -We will not be able to access loadpage.html
	4. Configure CORS - Configuring CORS in mycorstestbucket will allow index.html to access loadpage.html
==============================
Overview of CloudFront - Content Delivery Network
	A system of distributed servers which deliver webpages and other web content.
		Easy and cost effective way to distribute content with low latency and high data transfer speeds.
------------------------------
CloudFront Terminology
	1. CloudFront Edge Location - This is the location where content is cached. Separate to an AWS Region/AZ
	2. CloudFront Origin - This is the origin of all thw filws that the distribution will server, Can be an S3 Bucket, anEC2 Instance, an ELB, Route53
	3. CloudFront Distribution - This is the name given to the Origin and configuration settings for the content you wish to distribute using CF (CDN)
------------------------------
Deliver your entire website.
	Global network of 200+ edge locations
	- Requests for your content are automatically routed to the nearest edge location, so content is delivered with the best possible performance
	- Allows toy to optimize performance for users accessing your website from all around the world
------------------------------
CloudFront
	1. Optimized - Optimized to work with other Amazon Web Services
	2. Integrated with AWS Services - S3, EC2, ELB, and Route 53
	3. Your own Server - It also works seamlessly with any non-AWS origin server, which stores the original, definitive versions of your files.
------------------------------
Objects are cached for a time which is their TTL
	The default TTL = 1d, and when the TTL is up, the object is automatically created from the cache
	You can clear an object from the cache yourself before the TTL is up, but you will be charged.
------------------------------
CloudFront & S3 Transfer Acceleration
	S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your end users, and an S3 bucket.

	As the data arrives at an edge location, it is routed to Amazon S3, over an optimized network path
==============================
DEMO Configuring CloudFront
	1. Create an S3 bucket
	2. Access an image from the S3 bucket
	3. Create a cloudFront distribution
	4. Access the image using CF- compare the response time
------------------------------
CloudFront with Origin Access Identity
	Exam Tips
	1. Content Delivery Network - CloudFront can speed up the delivery of your static content to viewers around the world
	2. Origin Access Identity (OAI) - An OAI is a special CloudFront that can access the files in our bucket and server them to users.
	3.Restrict Access - OAI allows us to restrict access to the content of our bucket, so that all users must use the CloudFront URL instead of a direct S3 URL
=============================
Understanding CloudFront Allowed Methods
	What Are CloudFront AllowedMethods?
	Supported HTTP Methods
	Which Should i Choose?
	Exam Tips
-------------------------------
When you create sa CloudFront distribution, you need to specify which HTTP methods you distribution will support.
	Allowed HTTP methods: 
	read 1. GET, HEAD
	read 2. GET, HEAD. OPTIONS
	read/write 3. GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE
------------------------------
GET - read data - read a web page
HEAD - inspect resource headers, like GET but without body - Read a web page header
PUT - Send data for create new or replace existing  idempotent - Update data or change the status of a resource
PATCH -Partially modify a resource - modify the content of a shoping cart.
POST - create of update, NOT idempotent - Comment on a blog port
DELETE - delete data - remove email from a mailing list 
OPTIONS - find what HTTP methods are supported by teh given URL - Receive a list of supported HTTP methods
===============================
Introducing Athena
	What is Athena?
	Athena Use Cases
	Exam Tips
-------------------------------
What is Athena ?
	Athena enables you to run standard SQL queries on data stored in S3
	1. Serverless - nothing to provision, pay per query / per TB scanned
	2. Easy - no need to setup complex Extract/Transform/Load (ETL) process
	3. Integrated - Works directly with data stored in S3
------------------------------
Use Cases:
	1. Query Log files- Query log files stored in S3 e.g. ELB logs, S3 access logs, etc
	2. Generate business reports - Generate Business reports on data stored in S3
	3. Perform cost analysis - Analyze AWS coast and Usage reports
	4. Analyze Click-stream - Run queries on click-stream data
-------------------------------
Exam Tips:
	1. Interactive Query - Athena is an interactive query service.
	2. Standard SQL - Allows you to query data stored in S3 using standard SQL
	3. Serverless - You don't need to configure any infrastructure to use Athena
===============================
Athena Demo
	1. configure a Trial in CloudTrial - it will generate an audit log of all activity on our account
	2. CloudTrial sends a logs to S3 - our trail will store the logs it creates in a new S3 bucket
	3. Create an Athena table  - use standard SQL to query the data stored in the S3 bucket
------------------------------

	2. 


		






	




	



















	
	
	 
	
	
































	
