Amazon SQS
	A message querue service.
	Enables web service applications to quickly and reliably queue messages that one component in the application generates 
		for another component to consume
	A queue is a temporary repository for messages awaiting proxess
---------------
Decoupling toyr Infrastructur - Visibility 
	if message was not processed during timeout - it will be visible for processing again
---------------
SQS Features
  1. Decoupling Application Components - Decouple the components of an application so they run independently, easing message management between components
  2. Store messages - Any component of a distributed application can store messages in the queue. Messages can contain up to 256KB of text in any format
  3. Retrive Messages - Any component can later retrive the messages proframatically using the Amazon SQS API
--------------
A Buffer between components
	SQS - a Buffer between the component receiving the data for processing 
	and the component producing and saving data
--------------
Resolve Scheduling Issues
	The quewue resolves issues that arise if the producer is producing work faster than the consumer can process it, or if the producer or a consumer 
		are only intermittently connected to the network
--------------
SQS Key Facts
  1. Pull-based - SQS is pull-based, not published-based.
  2. 256 KB - Messages are 256 KB size
  3. Text Data - Including XML, JSON, and unformated text.
  4. Guarantee - Messages will be processed at least once.
  5. Up to 14 Days - Messages can be keept in the queue from 1 min to 14 days
  6. Default is four Days - The default retention period is four days.
--------------
Exam Tips 
	Distributed message queueing system
	Allows us to decople the components of an application so that they are independent.
	Pull-based, not push-based.
==============
SQS QUeue Types
  1. Standard queues are the default, which provide best-effort ordering
  2. FIFO
---------------
Standard Queues
 1. Unlimited Transactions - Nearly-unlimited number of transactions per second
 2. Guarantee - Guaranees that a message is delivered at least once
 3. Best-Affort Ordering - Standard queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they are sent.
     Occasionally (because of the highly-distributed architecture that allows high throughput), more than one copy of a message might be delivered out of order.
---------------
Standard Queues - Best-effort Ordering
	4	3	2
	    3	    5	    1

FIFO Queues
1. FIFO delivery - the order in which messages are sent and recieved is strictly preserver.
2. Exactly-Once Processing - A message is delivered once and remains available untill a consumer processing and deletes it. Duplicates are not introduced
3. 300 TPS Limit - FIFO queues are limited to 300 ransactions per sec(TPS), but have all the capabilities of standard queues.

	1	2	3	4	5
----------------
Standard VS FIFO
	Standard :
		Best-effort ordering
		Message delivered at least once
		Occasional duplicates
		The default queue type
	FIFO :
		FIFO message order is strictly preserverd
		Messages are delivered once
		No Duplicates
		Good for banking transactions which need to happen in a strict order.
==================
SQS Settings
	Visibility timeout :
		Is the amount of time that message is visible in the SQS queue after a reader picks up that message
		Ideally, the jpb will be processed before the visibility time out expires, and the message will then be deleted from the queue.
		If the job is not processed  within tha time, the message will become visible again and another reader will process it.
-----------------
Change the Visibility Timeout
	1. Default - the default visibility timeout is 30 seconds
	2. Increase If Necessary - Increase it if the task tales more than 30 seconds
	3. Maximum - The maximum is 12 hours.
-----------------
Short Polling VS Long Polling
	Short Polling:
		Returns a response immediatelly even if the message queue being polled is empty
		This can result in a lot of empty responses if nothing is in the queue.
		You will still pay for these responses
	Long Polling
		Periodically polls the queue.
		Doesn't return a response untill a message arrives in the message queue or the long poll times out.
		Can save money
		Long polling is generally preferable to short polling
==================
SQS Delay Queues - postpone delivery of new messages
	Postpone delivery of new messages to a queue for a number of seconds
	Messages sent to the Delay Queue remain invisible to consumers for the duration of the delay period
	Default delay is 0 seconds, maximum is 900
	For standard queues, changing the setting doesn't affect the delay of messages already in the queue, only new messages
	For FIFO queues, this affects the delay of messages already in the queue
-------------------
When should you use a Delay Queue?
	Large distributed applications which may need to introduce a delay to an antire queue of messages 
	You need to apply a delay to an entire queue of messages
	e.g. adding a delay of a few seconds, to allow for updates to your sales and stock control databases before 
		sending a notification to a consumer confirming an online transaction
------------------
Managing Large SQS Messages
	Best Proctice For Messaging Large SQS Messages Using S3
		For large SQS messages - 256KB up to 2GB in size
		Use S3 to store the messages
		Use Amazon SQS Extended Client Library for Java to manage them
		(You'll also need the AWS SDK for Java) - provides an API for S3 bucket and object operations

	SQS(2GB) --SQS Ext Client Lib for Java-->AWS SDK for Java ==> S3
------------------
SQS Extended Client Lib for Java allows you to :
	Specify that messages are always stored in Amazon S3 OR only messages > 256 KB
	Send a message which references a message object stored in S3
	Get a message object from S3
	Delete a message object from S3
------------------
You need : 
	AWS SDK for Java
	SQS Extended Client Lib for Java
	An S3 bucket
Can't Use:
	AWS CLI
	AWS Management Console/SQS Console
	SQS API
	Any other AWS SDK
---------------------
Exam tips:
	SQS Delay Queue
	1. Postpone delivery of new messages
	2. Messages in delay Queue remain invisible for the duration of the delay period(0-900s)
	3. Larger distributed applications which may need to introduce a delay in processing

	Managing large Messages in S3
	1. Store large messages - 256KB - 2GB in S3
	2. AWS SDK for Java
	3. Amazon SQS Extended Client Lib for Java
	Cannot use : AWS CLI, AWS Management Console/ SQS Console. SQS API   y
========================
SNS
	A web service that makes it easy to set up operate, and send notifications from the Cloud.
	Messages sent from an appliaction can be immediately  delivered to subscribers or other applications
----------------------
SNS - A Notification Service
	1. Push Notifications - To devices (e.g. Apple, Google, FireOS, Windows, Android)
	2. SMS and Email - SMS text messages or email to Amazon Simple Queue Service (SQS) queue or any HTTP endpoint
	3. Lambda - Trigger Lambda functions to process the message, push to another SNS topic, or send the message to another AWS service.
---------------------
How it works:
	A pub-sub model.
	Publish and subscribe
	Applications Publish or PUSH messages to a TOPIC
	Subscriber RECEIVE messages from a TOPIC
----------------------
DUrable Storage
	Prevents messages from being lost
	All messages published to Amazon SNS are stored redundantly across multiple AZ
---------------------
SNS Benefits
	1. Instantaneous - push -based delivery (no polling)
	2. Simple - simple APIs and easy integration with applications.
	3. Flexible message delivery over multiple transport protocols
	4. Inexpensive - pay-as-you-go model with no up-front cost
	5. Easy To Configure - Web-based AWS Management Consloe offers the simplicity of a point-and-click interface.
	6. Managed Service - With all the high availability and durability features needed for a prod environment
---------------------
SNS VS SQS

	SNS :
		Messaging service
		SBS is push-based
		Think push notifications
	SQS :
		Messaging Service
		SQS is pull based
		Think polling the queue for messages
-----------------------
Exam tips:
	Notifications - scalable and highly available notification service which allows us to send push notifications from the cloud
	Message Formats - SMS text message, email. Amazon SImple Queue Service (SQS) queues, or any HTTP endpoint
	Pub-Sub - model whereby users subscribe to topics. Push mechanizm, rather than a pull (or poll) mechanizm
=====================
SNS Versus SES
	Simple Email Service 
	1. Scalable and Highly Available Email - Designed to help marketing teams and application developers send marketing, notification, and transactional
	emails to their customers using a pay-as-you-go model
	2. Send and Receive Emails - Can also be used to receive emails with incoming mails delivered to an S3 bucket.
	3. Trigger Lambda and SNS - incoming emails can be used to trigger Lambda functions and SNS notifications.
--------------------
Use Cases
	1. Automated Emails - Notification that there is a new post in a discussion forum that you moderate
	2. Online Purchases - Purchase confirmations, shipping notifications, and order status updates.
	3. Marketing Emails - Marketing Emails - Marketing communications, advertisements, newsletters, special offers, new products, and Black Friday deals.
-------------------
SES vs SNS
	SES : 
	1. Email messaging service
	2. Can Trigger a Lambda function or SNS notification.
	3. Can be used for both incoming and outgoing email
	4. An email adress is all that is required to start sending messages

	SNS: 
	1. Pub/Sub messaging service; formats include SMS. HTTP, SQS, email
	2. Can trigger a lambda function.
	3. Can fanout messages to a large number of recipients (replicate and push messages to a multiple endpoints and formats)
	4. Consumers must subscribe to a topic to receive the notifications
-----------------------
Exam tips :
	SES is for email only
	SES can be used for incoming and outgoing emails
	It is not subscription-based, you only need to know the email address

	SNS supports : SMS, SQS, HTTP, email
	Push notifications only, Not for receiving notifications
	Pub/Sub model; customers must subscribe to a topic
	Fanout - Can fanout messages to a large number of recipients (e.g. to multiple SQS queues, HTTP endpoints, and email addresses)
=======================
Kinesis   
	A Family of services that enables you to collect, process and analyze streaming data in real time
	Allows you to build custom applications for your own business needs.
	Kinesis is originally a Greek word, meaning movement or motion. 
	Amazon Kinesis deals with data that is in motion, or sttreaming data
---------------
What is Streaming Data ?
	Data generated continuosly by thousands of data sources that typically send in the data records simultaneously and in small size (kilobytes).
	1. Financial transactions
	2. Stock prices
	3. Game Data (as the gamer players)
	4. Social media feeds
	5. Locatin-tracking data (Uber)
	6. IoT sensors
	7. Clickstream data
	8. Log files
-----------------
4 Core Services
	Kinesis Streams - Stream Data and video to allow you to build custom applicationsthat process data in real time.
		DataStreams Service
		VideoStreams Service
	Kinesis yData Firehouse - Capture, Transform, and load data streams into AWS data stores to enable near real-time analytics with BI tools
	Kinesis Data Analytics - Analyze, query, and transform streamed data in real time using 'standard SQL'. Store the results in an AWS data store
--------------------
Kinesis Shards
	Kinesis streams are made up of shards.
	Each shard is a sequence of one or more data records and provides a fixed unit of capacity.
	Five reads per second. The  max total read rate is 2 MB per second
	1000 writes per second.  The max total write rate is 1MB per second.
-------------------
The Data capacity of the stream is determined by the number of shards.
If the data rate increases, you can increase the capacity on your stream by increasing the number of shards
All in Order - Each record in the stream has a unique sequence number that identifies it.
With Kinesisi streams, the order of records is maintained
--------------------
Kinesis Video Streams - Securely stream video from connected devices to AWS
	Video can be used for analytics and machine learning.
--------------------
Kinesis Firehose
	data in firehose may be processed with Lambda
	No shards
	No EC2 consumers
	BI(business Intelligence) tools
	Result will be puhed to S3, Redshift, OpenSearch ...
--------------------
Kinesis Data Analytics
	gets data from Kinesis data stream, and firehose for future analysisi with sql queries
--------------------
Exam Tips    
 Understand the difference
	Streams:  Capture and store streaming video and data. Consumer applications process and analyze the data in real time.
	Firehose:  Capture, transform, and load data continuously into AWS 'data stores'. 
		   Existing BI applications and tools can be used for near real-time analytics of the stored data.
	Analytics: 'Real-time analytics' using standard 'SQL' on data 'received by Kinesis Data Streams and Kinesis data Firehose'.
		    Stores the processed data in AWS data stores(e.g. S3., Redshift, or OpenSearch).
====================
Kinesis Shards vs Consumers

Kinesis Recap:
	The data capacity of your stream is the sum total capacity of it's shards
	Per shard:
	    5 readstransactions per secind, up to a max of 2MB per sec
	    1000 write records per second, up to a max of 1Mb per second.
	As your data rate increases, you increase the number of shards (resharding).
--------------------
Kinesis CLient Library
	The KCL ensures that for every shard there is a record processor.
	Manages the number of record processors relative to the number of shards & consumers
	If you have only one consumer, the KCL will create all the record processors on a single consumer.
	If you have two consumers it will load balance and create half the processors on one instance and half on another
-------------------
Scaling out the consumers
	With KCL, generally you should ensure that the number of instances does not exceed the number of shards(except for failure or standby purposes).
	You never need multiple instances to handle the processing load of one shard
	However, one worker can process multiple shards

	2 x consumers, processing 4 shards
	2 x record processors are running on each consumer, KCL handles the load balancing between the 2 consumers
-------------------
Scaling out the consumers
	It's fine if the number of shards exceeds the number of instances.
	Don't think that just because you reshard, that you need to add more instances.
	Instead, CPU utilisation is what should drive the quantity of consumer instances you have, NOT the number of shards in your Kinesis stream
	Use an Auto Scaling group, and base scaling decisions on CPU load on your cunsumers
-------------------
Exam Tips
	Kinesis Shards
		The Kinesis Client Library running on your consumers creates a record processor for each shardthat is being consumed by your instance.
		If you increase the number of shards, the KCL will add more record processors on your consumers
		CPU utilisation is what drive the quantity of consumer instances you have, NOT the number of shards in your Kinesis stream
		Use an Auto Scaling group, and base scaling decisions on CPU load on your consumers
===================
Introducing Elastic Beanstalk
	What is Elastic Beanstalk?
	What can it do for you?
	Exam Tips
--------------------
Deploy and scale Web Applications
	1. Supported languages : Java, .NET, PHP, Node.js, Python, Ruby, Go
	2. Supported Platforms : Apache Tomcat, Docker
	3. Developer Benefits : Focus on writing code, and don't worry about any of the underlying infrastructure needed to run the application
-------------------
What does Elastic Beanstalt Handle?
	1. Infrastructure : Provisioning infrastructure, load balancing, Auto Scaling, and application health monitoring
	2. Application platform : Installation and management of the application stack, 
		including patching and updates to your operating system and application platform
	3. You Are in Control : You have complete administrative control of the AWS resources. No additional charges for using Elastic Beanstalk.
-------------------
Lets Developer Develop
	Developers don't have to be sysadmins.
	You don't need to worry about any of the underlying infrastructure needed to run the application.
	Get your application to maket faster.
	Fastest and simplest way to deploy your application in AWS.
------------------
Exam Tips:
	Deploy and Scale : Deploys and scales your web applications, including the web application server pltform
	Programming Languages : Java, PHP, Python, Ruby, Go, .NET, Node.js
	Managed Platforms : Apache Tomcat, Docker.
	Provision AWS Resources : Provisions the AWS resources for you, e.g. EC2, RDS, S3, Elastic Load Balan,cers, Auto Scaling Groups, etc.
	Systems	Administration : OS and application server updates. Monitoring, metrics, and health checks are all included.
	Administrative Control : Can fully manage the EC2 instances for you, or you can take full administrative control. 
==================
Updating Elastic beanstalk
    Several Options For Deployment Updates: 
	1. All at once : Deploys to all hosta concurently.
	2. Rolling : Deploys the new version in batches.
	3. Rolling With Additional Batch : Launches an additional batch of instances. Then deploys the new version in batches.
	4. Immutable : Deploys the new version to a fresh group of instances before deleting the old instances. 
-------------------
Traffic Spliting : 
	Installs the new version on a new set of instances, like an immutable deployment. 
	Forwards a percentage of incoming client traffic to the new application version for evaluation.
-------------------
All at Once Deployment
	Deploys to all instances simultaneously.
	You will experience a total outage.
	Not ideal for mission-critical production systems. Because seite will be unavailable for duration time

4 instances
4 redeployed in one time

-------------------
All at Once Deployment-Rolling Back
	If the update fails, you need to roll back the changes by re-deploying the original version to all your instances.
	Resulting in another outage to get back to the previous version.
-------------------
Rolling Deployment Policy
	Deploys the new version in batches.
	Each batch is taken out of service while the deployment takes place.
	Your environment capacity will be reduced by the number of instances in a batch white the deployment takes place
	Not Ideal for performance sensitive systems

4 instances 
2 redeployed
after success
next 2 redeployed

-------------------
Rolling Deployment Policy-Rolling Back
	If the update fails, you need to perform an additional rolling update to roll back the changes
-------------------
Rolling  with Additional Batch
	Launches an additional batch of instances.
	Deploys the new version in batches.
	Maintains full capacity throughput the deployment.

4 instances
crated 2 more 
2 old stops
2 new created 
2 old stoped

------------------
Rolling With Additional BAtch - Rolling Back
	If you update fails, you need to perform an additional rolling update to roll back the changes
------------------
Immutable Deployment
	Only when the new instances pass their health checks, should the old instances be terminated

4 instances
creating new 4 instances
if test passed
4 old instances will be stopped
-------------------
Immutable deployment - Rolling back
	If a deployment fails, just delete the new instances. and check that LB points to working version 
	This is the preferred approach for mission sritical systems
-------------------
Traffic Splitting
	Enables Canary Testing 
		Installs the new version on a new set of instances just like an immutable deployment.
		Forwards a percentage of incoming client traffic to the new application version for a specified evaluation period.
		Version 1 - 90%   Version 2 - 10%
	
		If the new instances stay healthy, Elastic Beanstalk forwards 100% of the traffic to them, and terminates the old ones.
		Like the canary in the coal mine, this provides an early indication that something is wrong.
-------------------
Elastic Beanstalk Deployment types - Exam Tips
	1. All at Once - Involves a service interraption. Rolling back requires a further All at Once update.
	2. Rolling - Reduces capacity during deployment. Rolling back requires a further Rolling update.
	3. Rolling with Additional Batch - Maintains full capacity. Rolling back requires a further Rolling updates.
	4. Immutable - Maintains full capacity. To roll back, delete the new instances. Prefered option for mission critical production systems. 
	5. Traffic Splitting - Performs an immutable deployment and then splits the traffic between the old and new deployment, enabling Canary Testing.
====================
Advanced Elastic Beanstalk
	Customizing Your Elastic Beanstalk Environment
		You can customize your 'Elastic Beanstalk environment' in a number of different ways.
		The configuration is different for Amazon Linux 1 and Amazon Linux 2
------------------
For Pre-Amazon Linux 2 Envs:
	Configuration file  : Define packages to install, create Linux users and groups, run shell commands, enable services, and configure load balancers.
	File formats : YAML, JSON
	Constraints : xThe file must have a .config extension and be inside a folder called .ebextension in the 
			top-level directory of your application source code bundle
------------------
myhealthcheckurl.config Example  for Amazon Linux 1 ONLY
{
"option_settings" : 
[
{
"namespace" : "aws:elasticbeanstalk:application", 
"option_name" : "My Application Healthcheck URL",
"value":"/healthcheck"
}
]
}

Configures an 'application health check URL' that will be used by a load balancer, which will make an HTTP request 
	to the specified path to check if the instances are healthy.
---------------------
Amazon Linux 2 has been available for a long time; however, you may still see .ebextensions mentioned in the exam.
---------------------
What about Amazon Linux 2 ? 
	AWS Elastic Beanstalk Developer Guide: 
		"On Amazon Linux 2 platforms, we highly recommend that you use 'Buildfile, Procfile, and platform hooks' 
		wheneverpossible to configure and run custom code on your environment instances during instance provisioning"
----------------------
Buildfile:
	Buildfile : For commands that run for 'short' periods, and then 'exit' upon task completion (e.g. running a shell scrupt)
	Root Directory : Create your Buildfile in the 'root' directory of your application source 
	Format : <process_name>:<command> 
		           make: ./build.sh <- reference a script in your source code bundle
----------------------
Procfile
	Procfile : 'long-running' application process (e.g. commandsto start and run your applicatin)
	Root Directory : Create a file called 'Procfile' in the 'root' directory of your application source
	Format : <process_name> : <command>
		web: bin/myserver
		app: bin/myapp
Elastic Beanstalk expects process defined in the Procfile to run continuously.
It monitors and restarts any processes that terminate.
----------------------
Customizing Amazon Linux 2 Environments - Platform Hooks
	Custom scripts or executable files that you would like Elastic Beanstalk to run at a 'chosen stage' of the EC2 provisioning process
	Started in dedicated 'directories' in your application source code

	.platform/hooks/prebuild - Files that you want Elastic Beanstalk to run 'before' it builds, set up and configures the application and web server.
	.platform/hooks/predeploy - Files that you want to run after it sets up and configures the application and web server but 'before it deploys' 
					them to the final runtime location.
	.platfirm/hooks/postdeploy - Files that run 'after' Elastic Beanstalk 'deploys' the application. - The last deployment workflow step.
----------------------
Advanced Elastic Beanstalk Exam Tips
  You can 'customize' your Elastic Beanstalk environment in a number of ways.

Amazon Linux 1 or 2
	The .ebextensions Folder - Locates in the 'top-level directory' of your application source code bundle.
				   Files must have a .config extension (e,g, myhealthcheckurl.config).
Amazon Linux 2 only
	Buildfile - Create a 'Buildfile' in the root directory of your app source for commands that 'exit' upon completion (e.g. shell script) 
	Procfile - Create a Procfile for 'long-running processes (e.g. custom commands to start your application)'
	Platform Hooks - Custom script or executable that run at 'various stages' when EC2 instances are provisioned.
		 .platform/hooks/prebuild
				/predeploy
				/postdeploy
======================
RDS and Elastic Beanstalk
	Integrating RDS With Elastic Beanstalk :
		Elastic Beanstalk Supports 2 ways if integrationg an RDS db with your Beanstalk environment.
		 1. Deploying RDS inside your Elastic Beanstalk env, - good for test 
		 2. outside of it. - good for prod
----------------------
For onnfigure outside : 
	1. Additional SG must be added to your env's ASG to allow EC2 communicate with RDS on port 3306
	2. You'll need to provide connection string info to you application servers using Elastic Beanstalk environment properties.
----------------------
Migrating Apps to Elastic Beanstalk 
	Scenarion
	Migrating Assistant Tool
	Exam Tips
----------------------
run .NET Migration Assistant - windows tool
----------------------
FOrmerly named the .NET Migration Assistant. 
Open-source, interactive 'PowerShell' utility that 'migrates' .NET apps from on-premises Windows servers to 'Elastic Beanstalk'

	

	
	
	


                                                                                              













	

	



 





	

	 




 







	












		 
	
		



	
		

	