AWS Monitoring, Troubleshooting & Audit
	
Why Monitoring is important
	We know how to deploy applications
		Safely
		Automatically
		Using Infrastructure as code
		Leveraging the best AWS components!
	Our applications are deployed, and our users don't care how we did it ...
	Our users only care that  the application is working
		Application latency: will it increase over time?
		Application outages: customer experience should not be degrated
		Users contacting the IT department or complaining is not a good outcome
		Troubleshooting and remediation
	Internal monitoring
		Can we prevent issues before they happen?
		Performance and cost
		Trends (scaling patterns)
		Learning and improvement
---------------------------------------------------------------------------------------------------
Monitoring in AWS
	AWS CloudWatch:
		Metrics: Collect and track key 	metrics
		Logs: Collect, monitor, analize, and store log files
		Events: Send notifications when certain events happen in your AWS
		Alarms: React in real-time to metrics/events
	AWS X-Ray:
		Troubleshooting application performance and errors
		Distributed tracing of microservices
	AWS CloudTrial:
		Internaal monitoring of API calls being made
		Audit changes to AWS Resources by your users
====================================================================================================  
CloudWatch metrics
	CloudWatch provides metrics for every services in AWS
	Metric is a variable to monitor (CPUUtilization, Networkin...)
	Metrics belong to namespaces
	Dimension  is an attribute of a metric (instance id, environment, etc)
	Up to 30 dimentions per metric
	Metrics have timestamps
	Can create CloudWatch dashboard of metrics
-------------------------------------------------------------------------------------------------------
EC2 Detailed monitoring
	EC2 instance metrics have metrics "every 5 minutes"
	With detailed monitoring (for a cost), you get data "every 1 minute"
	Use detailed monitoring if you want to scale faster for your ASG!
	The AWS Free Tier allows us to have 10 detailed monitoring metrics
	Note : EC2 Memory usage is by default not pushed (must be pushed from inside the instance as a customer metric)
========================================================================================================
CloudWatch Custom Metrics
	Possibility to define and send your own custom metrics to CloudWatch
	Example : memory (RAM) usage, disk space, number of logged in users ...
	Use API call PutMetricData
	Ability to use dimension (attributes) to segment metrics
		Instance.id
		Environment.name
	Metric resolution (StorageResolution- API patameter - two possible value):
		Standard : 1 min
	        High Resolution : 1/5/10/30 second(s) - Higher cost
	Important: Accepts metric data points two weeks  in the past and two hours in the future (make sure to configure your EC2 instance time correctly) 
=========================================================================================================
CloudWatch Logs
	Log groups: arbitrary name, usually representing an application
	Log stream : instances within application / log file/ conatiners
	Can define expiration policies (never expire, 1 day to 10 years...)
	CloudWatch Logs can send logs to : 
		Amazon S3 (exports)
		Kinesis Data Streams
		Kinesisi Data Firehose
		AWS Lambda
		OpenSearch
	Logs are encrypted by default
	Can setup KMS-based encryption with your own keys
-----------------------------------------------------------------------------------------------------------
CloudWatch Logs - Sources
	SDK, CloudWatch Logs Agent, CloudWatch Unified Agent
	Elastic Beanstalk: collection of logs from application
	ECS: collection from containers
	AWS Lambda: collection form function logs
	VPC Flow Logs: VPC specific logs 
	Api Gateway
	CloudTrial based on filter
	Route 53: Log DNS queries
--------------------------------------------------------------------------------------------------------------
CloudWatch Logs Insights
	Search and analize log data stored in CloudWatch Logs
	Example : find a specific IP inside a log, occurrences of "ERROR" in your logs...
	Provides a purpose-build query language
		Automatically descovers firlds from AWS services and JSON log events
		Fetch desired event firlds, filter based on conditions, calculate aggregate statistics, sort events, limit number of events...
		Can save queries and add them to CloudWatch Dashboards
	Can query multiple Log Groups in different AWS accounts
	It's a query engine, not a real-time engine
---------------------------------------------------------------------------------------------------------------
CloudWatch Logs - S3 Export
	Log data can take up to 12 hours to become available for export
	The API call is CreateExportTask
	Not near-real time... use Logs Subscriptions instead
---------------------------------------------------------------------------------------------------------------
CloudWatch Logs Subscriptions
	Get a real-time log events from CloudWatch Logs for processing and analysis     
	Send to Kinesis Data Streams, Kinesis Data Firehose, or Lambda
	Subscription Filter - filter which logs are events delivered to your description

	CloudWatch Logs ----> Subscription Filter ----> Kinesis Data Streams ---> Kinesisi Data Firehose, Kinesis Data Analitics, EC2, Lambda
                                                           
                                                  ----> Kinesis Data Firehose |--> S3
                                                                               --> Open Search Service
                                                  ----> Lambda ---------------|
---------------------------------------------------------------------------------------------------------------------
CloudWatch Logs Aggregation Multi-Account & Multi Region

Account 1 ----> Subscription Filter ---| 
					-->Kinesisi Data Stream  ---> Kinesis Data Firehose ---> S3
Account 2 ----> Subscription Filter ---|     
-----------------------------------------------------------------------------------------------------------------------
CloudWatch Logs Sybscription
	Cross-Account Subscription - send log events to resources in a different AWS account (KDS, KDF)  

	Example : 
		Account 1 [CloudWatch Logs ---> Subscription Filter] --> Account 2 [Subscription Destination --> Kinesis Data Stream]
		                                                                                                        ^
						can be assumed ------------>IAM Role    --> allow put record -----------|		                 

						                            (Destinatoion Access Policiy)

IAM Role (Cross-Account)
{
    "Statement": [
        {
  	    "Effect": "Allow",
	    "Action": "kinesis:PutRecord",
	    "Resource":"arn:aws:kinesis:us-east-1:<recipient accountId>:stream/RecipientStream"
        }
    ] 
}

Destination Access Policy
{
    "Version":"20-01-2020",
    "Statement":[
	{
	    "Sid":"",
	    "Effect":"Allow",
	    "Principal":{
		"AWS":"<sender account ID>"
	    },
	    "Action":"logs:PutSubscriptionFilter",
	    "Resource":"arn:aws:logs:us-east-1:<recipient account ID>:destination:testDestination"
	}
    ]
}
=============================================================================================================================================

CloudWatch Logs for EC2
	By default, no logs from your EC2 machine will go to CLoudWatch
	You need to run a CloudWatch agent on EC2 to push the log files you want
	Make sure IAM permissions are correct
	The CloudWatch log agent can be setup on-permises too
---------------------------------------------------------------------------------------------------------------------------------------------
CloudWatch Logs Agent & Unified Agent
	For virtual servers (EC2 instances, on-permise servers...)
	CloudWatch Logs Agent
		Old version of the agent
		Can only send to CloudWatch Logs

	CloudWatch Unified Agent
		Collect additional system-level metrics such as RAM, processes, etc...
		Collect logs to send to CloudWatch Logs
		Centralize configuration using SSM Parameter Store
-----------------------------------------------------------------------------------------------------------------------------------------------
CloudWatch Unified Agent - Metrics
	Collected directly on your Linux server / EC2 instance
	CPU (active, guest, idle, system, user, steal)
	Disk Metrics (free, used, total), Disk IO (writes, reads, bytes, iops)
	RAM (free, inactive, used, total, cached)
	Nested (number of TCP and UDP connections, net packets, bytes)
	Process (total, dead, bloqued, idle, running, sleep)
	Swap Space (free, used, used %)

	Reminder: out-of-the box metrics for EC2 - disk, CPU, network (high level)
===============================================================================================================================================
CloudWatch Logs Metric Filter
	CloudWatch Logs can use filter expressions
		For example, find a specific IP inside of a log
		Or count occurrences of "ERROR" in your logs
		Metric filters can be used to trigger alarms
	Filters do not retroactively filter data, Filters only publish the metric data points for events that happen after the filter was created
	Ability to specify up to 3 Dimensions for the Metric Filter (optionsl)

EC2 [CW Logs Agent] ---> CW Logs----> Metric Filter ---> CW Alarm ---> SNS
=================================================================================================================================================
CloudWatch alarms
	Alarms are used to trigger notifications for any metric
	Various options (sampling, %, max, min, etc...)
	Alarm States: 
		OK
		INSUFFICIENT_DATA (not enough data)
		ALARM
	Period:
		Lenght of time in seconds to evaluate the metric
		High resolution custom metrics : 10,30sec of multiples of 60 sec
-------------------------------------------------------------------------------------------------------------------------------------------------
CloudWatch Alarm Targets
	Stop, Terminate, Reboot, or Recover an EC2 Instance
	Trigger Auto Scaling Actions
	Send notification to SNS (from which you can do pretty much anything) 

------------------------------------------------------------------------------------------------------------------------------------------------
CloudWatch Alarms - Composite Alarms
	CloudWatch are on a single metric
	Composite Alarms are monitoring the states of multiple other alarms
	AND and OR conditions
	Helpful to reduce "alarm nise" by creating complex composite alarms

	Example :
	            <-------  CPU Alarm
               EC2                           -----composite CPU + Network Alarm ----> SNS
                    <-------  Network Alarm
--------------------------------------------------------------------------------------------------------------------------------------------------
EC2 Instance Recovery
	Status Check
		Instabce status = check the EC2 VM
		System status = check the underlying hardware

		EC2 <--------monitor------ CloudWatch Alarm--------alert----------->SNS Topic
		 ^                                 |
		 |---------------------------------|
                        Instance Recovery

	Recovery : Same Private, Public, Elastic IP, metadate, placement group 
--------------------------------------------------------------------------------------------------------------------------------------------------
CloudWatch Alarm: good to know
	Alarms can be created on CloudWatch Logs Metrics Filters
	
	CW Logs+Filter ----------> CW Alarm -----alert----> SNS

	Yo test alarms and notifications, set the alarm state to Alarm using CLI
		aws cloudwatch set-alarm-state --alarm-name "myalarm" --state-value ALARM --state-reason "testing purposes"

	For check Alarms : set alarm state : set-alarm-state
===================================================================================================================================================
CloudWatch Synthetics Canary
	Configurable script that monitor you APIs, URLs,Websites,...
	Reproduce what your customers do programmically to find assues before customers are impacted
	Checks the availability and latency of your endpoints and can store load time data and screenshots of yhe UI
	Integration with CloudWatch Alarms
	Scripts writen in Node.js or Python
	Programmatic access to a headless google Chrome browser
	Can run once or on a regular schedule
------------------------------------------------------------------------------------------------------------------------------------------------------
Cloudwatch Synthetics Canary Blueprints
	Hearbeat Monitor - load URL, store screenshot and an HTTP archive file
	API Canary - test basic read and write functions of REST APIs
	Broken Link Checker - check all links inside the URL that you are testing
	Visual Monitoring - compare a screenshot taken during a canary run with a baseline screenshot
	Canary Recorder - used with CloudWatch Synthetics Recorder (record your actions on a website and automatically generates a script for that)
	GUI Workflow Builder - verifies that actions can be taken on your webpage (e.g. test a webpage with a login form)
=================================================================================================================================================
Amazon EventBridge (formerly - before CloudWatch Events)
	Schedule : Cron jobs (schedule scripts)
		Example : Schedule Every Hour -------> Trigger script on Lambda function

	Event Pattern : Event rules to react to service doing something
		Example : IAM Root User Sign in Event  ---------> SNS Topic with Emaol Notifications

	Trigger Lambda functions, send SQS/SNS messages...
--------------------------------------------------------------------------------------------------------------------------------------------------
Amazon EventBridge Rules
	
	EC2 Instances(ex. Start event)                                           compute : Lambda, AWS BAtch, ECS Task
	Code Builder(ex. failed Build)                                           Integration : SQS, SNS, Kinesisi Data Streams
	S3 Event (ex. wupload objects)                                           Orchestration : Step Function, Code Pipeline, CodeBuilder
	Trusted Advisor(ex. new finding) ---mey be a filter--> EventBridge-----> Maintenance : SSM, EC2 Actions
	CloudTrial(Any api call)
	Schedule or cron(ex. every hour)
----------------------------------------------------------------------------------------------------------------------------------------------------
Amazon EventBridge
	Event buses can be accessed by other AWS accounts using Resource-based Policies
	You can archive events (all/filter) sent to an event bus (indefinitely or set period)
	Ability to replay archived events
----------------------------------------------------------------------------------------------------------------------------------------------------
EventBridge - Schema Registry
	EventBridge can analyze the events in your bus and infer the schema
	The Schema Registry allows you to generate code for your application, that will know in advance how data is structures in the event bus
	Schema can be versioned
----------------------------------------------------------------------------------------------------------------------------------------------------
EventBridge - Resource-based Policy
	Manage permissions for a specific Event Bus
	Example: Allow/Deny events from another AWS account or AWS region
	Use case: aggregate all events from your AWS Organization in a single  AWS account or AWS region

{
    "Version":"2012-10-17",
    "Statement":[
    {
	"Effect":"Allow",
	"Action":"events:PutEvents",
	"Principal":{"AWS":<src accountID>},
	"Resource":"arn:aws:events:us-east-1:<dst accountId>:event-bus/central-event-bus"
    }
  ]
}
=========================================================================
X-Ray Overview
	Debuging in Production, the good old way :
		Test locally 
		Add log statements everywhere
		Re-deploy in production
	Log formats differ across applications using CloudWatch and analylics is hard
	Debugging monolith "easy", distributed services "hard"
	No common views of your entire architecture!

	Enter.... AWS X-Ray! 
----------------------------------------------------------------------
AWS X-Ray Visual analysis of our applications
	show how many error was got for any service
	how mant requests	
----------------------------------------------------------------------
X-Ray advantages
	Troubleshooting performance (bottlenecks)
	Understand dependencies in a microservice architecture
	Pinpoint service issues
	Review request behavior
	Find errors and exceptions
	Are we meeting time SLA?
	Where ri am throttled?
	Identify users that are impacted
-----------------------------------------------------------------------
X-Ray compatibility
	AWS Lambda
	Elastic Beanstalk
	ECS
	ELB
	API Gateway
	ECS Instances or any application server (even on premise)
-----------------------------------------------------------------------
AWS X-Ray Leverages Tracing
	Tracing is an end to end way to following a "request"
	Each component dealing with the request adds its own "trace"
	Tracing is made of segments (+ sub segments)
	Anotations can be added to trace to provide extra-information
	Ability to trace:	
		Every request
		Sample request(as a % for example or a rate per minute)
	X-Ray Security:
		IAM for authorization
		KMS for encryption at rest
-------------------------------------------------------------------------
X-Ray - how to enable ?
	1. Your code (Java, Python, Go, Node.js, .NET) must import the AWS X-Ray SDK
		Very little code modification needed
		The application SDK will then capture
			Calls to AWS services
			HTTP/HTTPS requests
			Database Calls (MySQL, PostgresSQL, DynamoDB)
			Queue calls (SQS)
	2. Install the X-Ray daemon or enable X-Ray AWS Integration
		X-Ray daemon works as a low level UDP packet interceptor (Linux, Windows, Mac ...)
		AWS Lambda/other AWS services already run the X-Ray daemon for you
		Each application must have the IAM rights to write data to X-Ray

EC2 Instance = [App Code + AWS X-Ray SDK, ---traces--->  X-Ray Daemon Running on machine ] ---send batch every 1 sec ---> AWS X-Ray
---------------------------------------------------------------------------
X-Ray magic
	X-Ray service collects data from all the different services
	Service map is computed from all the segments and traces
	X-Ray is graphical, so even non technical people can help troubleshoot
-----------------------------------------------------------------------------
AWS X-Ray Triubleshooting
	If X-Ray is not working on EC2
		Ensure the EC2 IAM Role has the proper permissions
		Ensure the EC2 instance is running the X-Ray Daemon

	To enable on AWS Lambda:
		Ensure it has an IAM execution role with proper policy (AWSX-RayWriteOnlyAccess)
		Ensure that X-Ray is imported in the code
		Enable Lambda X-Ray Active Tracing
================================================================================
X-Ray Instrumentation in your code
	Instrumentation means the measure of product's performance, diagnose errors, and to write trace information
	To instrument your application code, you use the X-Ray SDK
	Many SDK require only configuration changes
	You can modify your application code to customize and annotation the data that the SDK sends to X-Ray, using interceptors, filters, handlers, middleware

Example Node.js:
var app = express();
var AWSXRay=require('aws-xray-sdk');
app.use(AWSXRay.express,openSegment('MyApp'));
app.get('/', function(req, res){
res.sender('index');
})		
app.use(AWSXRay.express.closeSegment());
------------------------------------------------------------------------------------
X-Ray Concepts
	Segments: each application/service will send them
	Subsegments: if you need more details in your segment
	Trace: segments collected together to form an and-to-end trace
	Sampling: decrease the amount of requests sent to X-Ray, reduce cost
	Annotations: Key Value pairs, not indexed, not used for searching

	The X-Ray daemon/agent has a config to send traces cross account:
		make sure the IAM permissions are correct - the agent will assume the role
		This allows to have a central account for all your application tracing
-------------------------------------------------------------------------------------
X-Ray Sampling Rules
	With sampling rules, you control the amount of data thet you record
	You can modify sampling rules without changing your code

	By default, the X-Ray SDK records the first request each second, and five percent of any additional requests.
	One request per second is the reservour, which ensure that at least one trace is recorded each seconf as long the service is serving requests.
	FIve persent is the rate at which additional requests beyond the reservoir size are sampled
-------------------------------------------------------------------------------------
X-Ray Custom Sampling Rules 
	You can create your own rules with the reservoir and rate

Example Higher minimum rate for POSTs
	Rule name - POST minimum
	Priority - 100
	Reservoir - 10
	Rate - 0.10
	Service Name - *
	Service Type - *
	Host - *
	HTTP Method - POST
	URL PAth - *
	Resource ARN - * 

Example Debugging rule to trace all requests for a problematic route
A High priority rule applied temporarily for debugging
	Rule name - DEBUG - history updates 
	Priority - 1       |
	Reservoit - 1      | ===> all trace will be sent to X-Ray
	Rate - 1           |
	Service Name - Scorekeep
	Service Type - *
	Host - *
	HTTP MEthod - PUT
	URL path - /history/*
	Resource ARN - *
==============================================================================================
X-Ray Write APIs(used by the X-Ray daemon)
{
    "Effect": "Allow",
    "Action": [
	"xray:PutTraceSegments",
	"xray:PutTelemetryRecords",
	"xray:GetSamplingRules",
	"xray:GetSamplingTargets",
	"xray:GetSamplingStatisticSummaries"
    ],
    "Resource":[
	"*"
    ]
}    

	PutTraceSegments: Uploadssegment documents to AWS X-Ray
	PutTelemetryRecords: Used by the AWS X-Ray daemon to upload telemetry.
		SegmentsReceivedCount,
		SegmentsRejectedCounts,
		BackendConnectionErrors...
	GetSamplingRules: Retrive all sampling rules(to know what/when to send)
	GetSamplingTargets & GetSamplingStatisticSummaries: advanced
	The X-Ray daemon needs to have an IAM policy authorizing the correct API calls to function correctly
------------------------------------------------------------------------------------------------
X-Ray Read APIs - continued

{
    "Effect":"Allow",
    "Action":[
	"xray:GetSamplingRules",
	"xray:GetSamplingTargets",
	"xray:GetSamplingStatisticsSummaries",
	"xray:BatchGetTraces",
	"xray:GetServiceGraph",
	"xray:GetTraceGraph",
	"xray:GetTraceSummaries",
	"xray:GetGroups",
	"xray:GetGroup",
	"xray:GetTimeSeriesServiceStatistics"
    ],
    "Resource":[
        "*"
    ]
}

	GetServiceGraph: main graph
	BatchGetTraces: Retries a list of traces specified by ID, Each trace is a collection of segment documents that originates from a single request.
	GetTraceSummaries: Retrives IDs and annotations for traces available for a specified time frame using an optional filter.
		to get the full traces, pass the trace IDs to BatchGetTraces
	GetTraceGraph: Retrives a service graph for one or more specific trace IDs.
-----------------------------------------------------------------------------------
X-Ray with Elastic Beanstalk
	AWS Elastic Beanstalk platforms include the X-Ray daemon
	You can run the daemon by setting an option in the Elastic Beanstalk console or with a configuration file (in .ebextensions/xray-daemon.config)
	
	oprion_setings : 
		aws:elasticbeanstalk:xray:
			XRayEnabled: true 

	Make sure to give your instance profile the correct IAM permissions so that the X-Ray daemon can function correctly
	Then make sure your applicatio code is instrumented  with the X-Ray SDK
	Note: The X-Ray daemon is not provided for Multicontainer Docker
=======================================================================================
ECS + X-Ray integration options
	1. ECS Cluster X-Ray Container as a Daemon 
		we have 2 EC2 each has 2 apps 
		every EC1 has 1 X-Ray daemon
	2. ECS Cluster X-Ray Container as a "Side Car"
		we have 2 EC2 each has 2 apps
		every app has own X-Ray daemon
	3. Fargate Cluster X-Ray Container as a "SIde Car"
--------------------------------------------------------------------------------------
x-Ray need port 2000 UDP 
======================================================================================
AWS Distro for OpenTelemetry
	Secure, production-ready AWS-supported distribution of the open-source project OpenTelemetry project
	Provides a single set of APIs, libraries, agents, and collector services
	Collects distributed traces and metrics from your apps
	Collects metadata from your AWS resouce and services
	Auto-instrumentation Agents to collect traces without changing your code
	Sendtraces and metrics to multiple AWS services and partner solutions
		X-Ray, CloudWatch, Prometheus...
	Instrument your apps running on AWS(e.g. EC2, ECS, EKS, Fargate, Lambda) as well as on-premises
	Migrate from X-Ray to AWS Distro for Telemetry if you want to standardize with open-source APIs from Telemetry 
		or send traces to multiple destinations simultaneously
---------------------------------------------------------------------------------------
AWS Distro for OpenTelemetry
	AWS Distro for OpenTelemetry
		1. Colect traces (collect data about the request from each app the request passes through)
		2. Collect Metrics (collect metrics from each app the request passes through)
		3. AWS Resources and Contextual Data (collect information about AWS resources and metadata where teh app is running)

		all this info may be sent to :
		1. AWS X-Ray
		2. Amazon CloudWatch
		3. Amazon Managed Service for Prometheus
		4. Partner Monitoring Solutions
======================================================================================================================
AWS CloudTrail
	Provides governance, compliance and audit for your AWS Account
	CloudTrial is enabled by default
	Get an history of events /API calls made within your AWS Account by:
		Console
		SDK
		CLI
		AWS Services
	Can put logs from CloudTrial into CLoudWatch Logs or S3
	A trial can be applied to All Regions(default) or a single Region.
	If a resource is deleted in AWS, investigate CloudTrial first!
---------------------------------------------------------------------------------------
CloudTrail Events
	Management Events: 
		Operations that are performed on resources in your AWS account
		Examples: 
			Configuring security (IAM AttachRolePolicy)
			Configure rules for routing data (Amazon EC2 CreateSubnet)
			Setting Up logging (AWS CloudTrial CreateTrial)
		Data Events
			By default, data events are not logged (because high volume operations)
			Amazon S3 object-level activity (ex: GetObject, DeleteObject, PutObject): can separate Read and Write Events
			AWS Lambda function execution activity (the Invoke API)
		CloudTrial Insights Events:
			Enable CloudTrial insights to detect unusual activity in your account:
				inaccurate resource provisioning
				hitting service limits
				Bursts of AWS IAM actions
				Gaps in periodic maintenance activity
			CloudTrial insights analyzes normal management events to create baseline
			And then continuously analizes write events to detect unusual patterns  send to :
				Anomalies appear in the CLoudTrial console
				Event is sent to S3
				An EventBridge event is generated (for automation needs)
-------------------------------------------------------------------------------------------
CloudTrial Events Retention
	Events are stored for 90 days in CloudTrial
	To Keep events beyond this period, log them to S3 and use Athent for analize
===============================================================================================
Amazon EventBridge - Intercept API Calls

	Examples:

	User ---delete Table--->DynamoDB ---log API Call---> CloudTrial ---event--->EventBridge ---alert---> SNS

	User---AssumeRole--->IAM Role---apicall logs---> CloudTrial---event---> EventBridge---> SNS
	
	User---AuthorizeSecurityGroupIngress--->SG (EC2)---apicall logs---> CloudTrial---event---> EventBridge---> SNS
	          edit SG inbound rules
=================================================================================================
CloudTrial vs CloudWatch vs X-Ray
	CloudTrial:
		Audit API calls made by users/services/AWS console
		Useful to detect unauthorized calls or root cause of changes
	CloudWatch:
		CloudWatch Metrics over time for monitoring
		CloudWatch Logs for storing application log
		CloudWatch Alarms to send notifications in case of unexpected metrics
	X-Ray:
		Automated Trace Analysis & Central Service Map Visualization
		Latency, Errors and fault analysis
		Request tracking across distributed systems
=======================================================================================================



	
	




	











 
	







	                                   

















