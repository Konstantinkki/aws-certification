Traditional Architecture
	Traditional applications leverage RDBMS databases
	These databases have the SQL query language
	Strong requirements about how the data should be modelled
	Ability to do query joins, aggregations, complexcomputations
	Vertical scaling(getting a more powerful CPU/RAM/IO)
	Horizontal scaling (increasing reading capability by adding EC2/RDS Read Replicas)
----------------------------------------------------------------------------------------------
NoSQL databases
	NoSQL databases are non-relational databases and are distributed
	NoSQL databases include MongoDB, DynamoDB,...
	NoSQL databases do not support query joins (or just limited support)
	All the data that is needed for a query is present in one row
	NoSQL databases don't perform aggregations such as "SUM","AVG",...
	NoSQL databases scale horizontally

	There's no "right or wrong" for NoSQL vs SQL, they just require to model the data differently and think about user queries differently
--------------------------------------------------------------------------------------------------
Amazon DYnamoDB
	Fully managed, highly available with replication across multiple AZs
	NoSQL database - not a relational database
	Scales to massive workloads, distributed database
	Millions of requests per seconds, trillions or fow, 100s of TB of storage
	Fast and consistent in performance (low latency on retrival)
	Integrated with IAM for security, authorization and administration
	Enables event driving programming with DynamoDB Streams
	Low cost and auto-scaling capabilities
	Standard & Infrequent access (IA) Table Class
-------------------------------------------------------------------------------------------------
DynamoDB - Basics
	DynamoDB is made of Tables 
	Each table has a Primary Key (must be decided at creation time)
	Each table can have an infinite number of items (= rows) 
	Each item has attributes (can be added over time - can be null)
	Maximum size of an item is 400KB
	Data types supported are:
		Scalar Types - String, Number, Binary, Boolean, Null
		Document Types - List, Map
		Set Types - String Set, Number Set, Binary Set
-------------------------------------------------------------------------------------------------
DynamoDB Primary Keys
	Option 1: Partition Key (HASH)
		Partition key must be unique for each item
		Partition key must be "diverse" so that the data is distributed
		Example: "User_ID" for a users table
	Option 2: Partition Key + Sort Key (HASH + RANGE)
		The combination must be unique for each item
		Data is grouped by partition key
		Example: user-games table, "User_ID" for PArtition key and "Game_ID" for Sort Kay

	  Primary Key 			   Attributes
Partition Key	  Sort Key
User_ID   	  Game_ID 		Score	Result 
--------------------------------------------------------------------------------------------------
DynamoDB - Partition Keya (Exersize)
	We're building a movie database
	What is the best Partition Key to maximize data distribution?
		movie_id
		producer_name
		leader_actor_name
		movie_language
	
	movie_id has the highest cardinality so it's a good candidate
	movie_language  - doesn't take many values and may be skewed towards English so it's not a great choice for the Partition Key
--------------------------------------------------------------------------------------------------
DynamoDB - Read/Write Capacity Modes
	Control how you manage your table's capacity (read/write throughput)
	Provisioned Mode (default)
		You specify the number of read/writes per second
		You need to plan capacity beforehand
		Pay for provisioned read&write capacity units
	On-Demand Mode
		Read/Writes automatically scale up/down with your workloads
		No capacity planning needed
		Pay for what you use, more expensive ($$$)
	You can switch between different modes once every 24 hours
---------------------------------------------------------------------------------------------------
R/W Capacity Modes - Provisioned
	Table must have provisioned read and write capacity units
	Read Capacity Units (RCU) - throughput for read
	Write Capacity Units (WCU) - throuhgput for writing
	Option to setup auto0scaling of throughput to meet demand
	Throughput can exceeded temporarily using "Burst Capacity"
	If Burst Capacity has been consumed, you'll get a "ProvisionedThroughputExceededException"
	It's then advised to do an exponentional backoff retry 
-----------------------------------------------------------------------------------------------------
DynamoDB - Write Capacity Units (WCU)
	One Write Capacity Units (WCU) represents one write per second for an item up to 1 KB in size
	If the items are larger then 1KB, more WCPUs are consumed
	
	Example 1: we write 10 items per second, with item size 2KB
		We need 10*(2KB/1KB)= 20 WCUs
	Example 2 : 
		we write 6 items per second, with item size 4.5KB
			6*(5KB/1KB) = 30 WCUs (4.5 gets rounded to the upper KB)
	Example 3: 
		we write 120 items per minute with item size 2KB
			We need (120/60)*(2kb/1kb) = 2WCUs
------------------------------------------------------------------------------------------------------
Strongly Consistent Read vs. Eventually Consistent Read 
	Eventually Consistent Read (default)
		if we read just after a write, it's possible we'll get some stale data because of replication
	Strongly Consistent Read
		if we read just after a write, we will get the correct data
		Set "COnsistentRead" patameter to true in API calls (GetItem, BatchGetItem, Query, Scan)
		Consumes twice the RCU
-------------------------------------------------------------------------------------------------------
DynamoDB Read Capacity Units (RCU)
	One Read Capacity Unit (RCU) represents one Strongly Consistent Read per second, 
	    or 2 Eventually Consistent Reads pe second, for an item up to 4KB in size
	If the item are larger than 4KB, more RCUs are consumed

	Examples : 
		10 Strongly Consistent Reads per second, with item size 4KB
			10*(4kb/4kb) = 10 RCUs
		16 Eventual Consistent Reads per second, with iten size 12KB
			16/2 * (12/4) = 24 RCUs
		10 Strongly Consistent Reads per second, with item size 6KB
			10*(8/4KB) = 20 RCUs (we must round up 6KB to 8KB)
-------------------------------------------------------------------------------------------------------
DynamoDB - Partitions Internal
	Data is stored in partitions
	Partition Kays go through a hashing algorithm to know to which partition they go to
	To compute the number of partitions:
		# of partitions(by capacity) = (RCUs total / 3000) + (WCUs total / 1000)
		# of partitions(by size) = Total size / 10GB
		# of partitions = ceil (max(#of partitions by capacity, #of partitions by size))
	WCUs and RCUs are spread evenly across partitions
-------------------------------------------------------------------------------------------------------
DynamoDB - Throttling
	If we exceed provisioned RCUs or WCUs, we get "ProvisionedThroughputExceededException"

	Reasons: 
		Hot Keyes = one partition key is being read too many times (e.g. popular item)
		Hot Partitions
		Very large items, remember RCU and WCU depends on size of items

	Solutions:
		Exponential backoff when exception is encountered (already in SDK)
		Distribute partition keys as much as possible
		If RCU issue, we can use DynamoDB Accelerator (DAX)
-------------------------------------------------------------------------------------------------------
R/W Capacity Modes - Ob-Demand
	Read/Write automatically scale up/down with your workloads
	No capacity planing needed (WCU/RCU)
	Unlimited  WCU & RCU, no throttle, more expensive
	You're charged for reada/writes that you use in terms of RRU and WRU
	Read Request Units (RRU) - throughput for reads (same as RCU)
	Write Request Units (WRU) - throughput for writes (same as WCU)
	2.5x more expensive than provisioned capacity (use with case)
	Use cases : unknown workloads, unpredictable application traffic, ,,,
========================================================================================================
DynamoDB - Writing Data
	PutItem
		Creates a new item or fully replace an old item (same Primary Kay)
		COnsumes WCUs
	UpdateItem
		Edits an existing item's attributes or adds a new item if it doesn't exist
		Can be used to implament Atomic Counters - a numeric attribute that's unconditionally incremented
	Conditional Writes
		Accept a write/update/delete only if conditions are met, otherwise returns an error 
		Helps with concurrent access to items
---------------------------------------------------------------------------------------------------------
DynamoDB - Reading Data
	GetItem
		Read based on primary Key
		Primary Key can be HASH or HASH+RANGE
		Eventually Consistent Read (default)
		Option to use Strongly Consistent Reads (more RCU - might take longer)
		ProjectionExpression can be specified to retrive only certain attributes
--------------------------------------------------------------------------------------------------------
DynamoDB - Reading Data (Query)
	Query returns items based on :
		KeyConditionExpression
			Partition Key value (must be = operator) - required
			Sort Key value (=,<,<=,>,>=,Between, Begins with) - optional
		FilterExpression
			Additional filtering after the Query operation (before data returned to you)
			Use only with non-key attributes (does not allow HASH or RANGE attributes)
	Returns:
		The number of items specified in Limit
		Or up to 1MB of data
	Ability to do pagination on the results
	Can query table, a Local Secondary Index, or a Global Secondary Index
--------------------------------------------------------------------------------------------------------
DynamoDB - Reading Data (Scan)
	"Scan" the entire table and then filter out data (inefficient)
	Returns up to 1 MB of data - use pagination to keep on reading
	Consumes a lot of RCU
	Limit impact using "Limit" or reduce the size of result and pause
	For faster performance, use "Paralles Scan"
		Multiple workers scan multiple data segments at the same time
		Increases the throughput and RCU consumed
		Limit the impact of parallel scans just like you would for Scan
	Can use ProjectionExpression & FilterExpression (no changes to RCU)
-------------------------------------------------------------------------------------------------------
DynamoDB - Deleting Data
	DeletionItem 
		Delete an individual Item
		Ability to perform a conditional delete
	DeleteTable
		Delete a whole table and all its items
		Much quicker deletion than calling DeleteItem on all items
-------------------------------------------------------------------------------------------------------
DynamoDB - Batch Operations
	Allows you to save latency by reducing the number of API calls
	Operations are done in parallel for better afficiency
	Part of a batch can fail; in which case we need to try again for the failed items

	BatchWriteItem
		Up to 25 Putitem and/or DeleteItem in one call
		Up to 16 MB of data writen, up to 400 KB of data per item
		Can't update items (Use "UpdateItem")
		UnprocessedItems for failed write operations (exponential  backoff or add WCU)
---------------------------------------------------------------------------------------------------------
DynamoDB - PartiQL
	SQL-compatible query language for DynamoDB
	Allows you to select, insert, update, and delete data in dynamoDB using SQL
	Run queries across multiple DynamoDB tables
	Run PartiQL queries from :
		AWS Management Console
		NoSQL Workbench for DynamoDB
		DynamoDB APIs
		AWS CLI
		AWS SDK
==========================================================================================================
DynamoDB - Conditional Writes
	For PutItem, UpdateItem, DeleteItem, and BatchWriteItem
	You can specify a Condition expression to determine which items should  be modified:
		attribute_exists
		attribute_not_exists
		attribute_type
		cantains(for String)
		begins_with(for String)
		ProductCategory IN (:cat1, :cat2) and Price between :low and :high

	Note: Filter Expression filters the results of read queries, while COndition Expressions are for write operations
----------------------------------------------------------------------------------------------------------
Conditional Writes - Example on Update Item
	aws dynamodb update-item\	
		--table-name ProductCatalog \
		--key '{"id":{"N":"456"}}'\
		--update-expression "SET Price = Price - :discount"\
		--condition-expression "Price > :limit" \
		--expression-attribute-values file://values.json
----------------------------------------------------------------------------------------------------------
Conditional Writes - Example on Delete item
	attribute_not_exists
		Only succeeds if the attribute doesn't exists yet (no value)
			aws dynamodb delete-item \	
			    --table-name ProductCatalog \ 
			    --key '{"id":{"N","456"}}' \
			    --condition-expression "attribute_not_exists(Price)"
	attribute_exists
		Opposite of attribute_not_exists
	                aws dynamodb delete-item \                                                                                  
                            --table-name ProductCatalog \                                           
                            --key '{"id":{"N","456"}}' \           
                            --condition-expression "attribute_exists(ProductReviews.OneStar)"
-----------------------------------------------------------------------------------------------------------
Conditional Writes - DO Not Overwrite Elements
	attribute_not_exists(partition_key)
		Make sure the item isn't overwritten

	atribute_not_exists(partition_key) and attribute_not_exists(sort_key)
		Make sure teh partition / sort key combination is not overwritten
-----------------------------------------------------------------------------------------------------------
Conditional Writes - Example of String Comparison
	begins_with - check if prefix matches
	contains - check if string is contained in another string
===========================================================================================================
DynamoDB - Local Secondary Index (LSI)
	"Alternative Sort Key" for your table (same "Partition Key" as that of base table) 
	The Sort Key consists of one scalar attribute (String, Number, Binary)
	Up to 5 Local Secondary Indexes per table
	Must be defined at table creation time
	Attribute Projections - can contain some or all the attributes of the base table (KEY_ONLY, INCLUDE, ALL)
	If we want to use PartitionKey+LSI

	Primary Key			Attributes
Partirion Key   Sort Key 	 LSI
User_ID		Game_ID		Game_TS		Score 		Result
-----------------------------------------------------------------------------------------------------------
DynamoDB - Global Secondary Index (GSI)
	Alternative Primary Key (HASH or HASH+RANGE)from the base table
	Speed up queries on non-key attributes
	The Index Key consists of scalar attributes(String, Number, or Binary)
	Attribute Projections - some or all the attributes of the base table (KEYS_ONLY, INCLUDE, ALL)
	Must provision RCUs & WCUs for the index
	Can be added/modified afre table creation
	
INDEX GSI (query)

Partition Key	 Sort Key	Attributes
Game_ID		 Game_TS	User_ID
-------------------------------------------------------------------------------------------------------------
DynamoDB - Indexes and Throttling
	Global Secondary Index (GSI):
		If the writes are throttled on the GSI, then the main table will be throttled!
		Even if the WCU on the main tables are fine
		Choose your GSI partition key carefully!
		Assign your WCU capacity carefully!

	Local Secondary Index (LSI):
		Uses the WCUs and RCUs of the main table
		No special throttling considerations
=======================================================================================================
DynamoDB - PartiQL
	Use a SQL-like syntax to manipulate DynamoDB tables
	Supports some (but not all) statements:
		INSERT
		UPDATE
		SELECT
		DELETE
	It supports Batch operations
=======================================================================================================
DynamoDB Optimistic Locking
	DynamoDB has a feature called "Conditional Writes"
	A strategy to ensure an item hasn't changed before you update/delete it
	Each item has an attribute that acts as a version number

Example:
	user 1 ---update John if version=1      first will be updated and second will be rejected
	user 2 --- update Lisa if version=1

=======================================================================================================
DynamoDB Accelerator (DAX)
	Full-managed, highly available, sampless in-memory cache for DynamoDB
	Microseconds latency for cached reads & queries
	Doesn't require application logic modification (compatible with existing DynamoDB APIs)
	Solves the "Hot Key" problem (too many reads)
	5 minutes TTL for cache (default)
	Up to 10 nodes in the cluster
	Multi AZ(3 nodes minimum recommended for production)
	Secure (Encryption at rest with KMS, VPC, IAM, CloudTrail, ...)
-------------------------------------------------------------------------------------------------------
DynamoDB Accelerator (DAX) vs. ElastiCache
	DynamoDB - for :
		Individual objects cache
		Query & Scan cache
	ElastiCache for:
		Store Aggregation Results
======================================================================================================
DynamoDB Streams
	Ordered stream of item-level modifications (create/update/delete) in a table
	Stream records can be:
		Sent to Kinesis Data Streams
		Read By AWS Lambda
		Read by Kinesis Client Library application
	Data Retention for up to 24 hours
	Use cases : 
		react to changes in real-time(welcom email to users)
		Analytics
		Insert into derivative tables
		Insert into OpenSearch Service
		Implement cross-egion replication

Exampel:                                                        ----->Lambda, KCL App ....

UserApp --- create/update/delete ---> Table --->DynamoDB Streams
                                                                ------> Kinesis Data Stream ...
------------------------------------------------------------------------------------------------------
DynamoDB Streams
	Ability to choose the information that will be written to the stream
		KEYS_ONLY - only the key attributes of the modified item 
		NEW_IMAGE - the entire item, as it appears after it was modified
		OLD_IMAGE - the entire item, as it appeared- before it was modified
		NEW_AND_OLD_IMAGES - both the new and the old images of the utem
	DynamoDB Streams are made of shards, just Kinesis Data Streams
	You don't provision shards, this is automated by AWS
	Records are not retroactively populated in a stream after enabling it
-----------------------------------------------------------------------------------------------------
DynamoDB Streams & AWS Lambda
	You need to define an Event Source Mapping to read from a DynamoDB Streams
	You need to ensure the Lanbda function has the appropriate permissions
	Your Lambda function is invoked synchronosly
-----------------------------------------------------------------------------------------------------
DynamoDB - Time to Live(TTL)	
	Automatically delete items after an expiry timestamp
	Doesn't consume any WCUs (i.e. no extra cost)
	The TTL attribute must be a "Number" data type with "Unix Epoch timestamp" value
	Expired Items deleted within 48 hours of expiration
	Expired items, that haven't been deleted, appears in reads/quries/scan
		(if you don't want them, filter them out)
	Expired items are deleted from both LSIs and GSIs
	A delete operation for each expired item enters the DynamoDB Streams(can help recover expired items)
	Use cases: reduce stored data by keeping only current items, adhere to regulatory obligations
=====================================================================================================
DynamoDB CLI - Good to Know
	--projection-expression: one or more attributes to retrive
	--filter-expression: filter items before returned to you

	General AWS CLI Pagination options (e.g., DynamoDB, S3, ...)
		--page-size: specify that AWS CLI retrives the full list of items but with a larger number of API
			calls instead one API call (default: 1000 items)
		--max-items: max number of items to show in the CLI (return NextToken)
		--starting-token: specify the last NextToken to retrive the next set of items	
======================================================================================================
DynamoDB Transactions
	Coordinated, all-or-nothing operations (add/update/delete) to multiple items across one or more tables
	Provides Atomicity, Consistency, Isolation and Durability (ACID)
	Read Modes - Eventual Consistency, Strong Consistency, Transactional
	Wrute Modes - Standard, Transactional
	Consumes 2x WCUs & RCUs
		DynamoDB performs 2 operations for every item (prepare & commit)
	Two operations:
		TransactGetItems - one or more GetItem operation
		TransactWriteItems - one or more PutItem, UpdateItem, and DeleteItem operations
	Use cases: financial transactions, managing orders, multiplayer games, ...
------------------------------------------------------------------------------------------------------
DynamoDB Transactions - Capacity Computations
	Important for the exam!
	Example 1: 3 transactional writes per second, with item size 5KB
		we need 3*(5/1KB)*2(transactional cost) = 30 WCUs
	Example 2: 5 transaction reads per secind, with item size 5KB
		we need 5*(8/4)*2(transactional cost) = 20 RCUs 
		 (5 get rounded to the upper 4KB)
=====================================================================================================
DynamoDB as Session State Cache
	it's common to use DynamoDB to store session state
	vs ElastiCache:
		ElastiCache is in-memory, but DynamoDB is serverless
		Both are key/value stores
	vs EFS
		EFS must be attachesd to EC2 instances as a network drive
	vs EBS & Instance Store:
		EBS & Instance Store can only be used for local caching, not shared caching
	vs S3:
		S3 is higher latency, and not meant for small objects
======================================================================================================
DynamoDB Write Sharing
	Imagine we have a voting application with two candidates, candidate A and candidate B
	If Partition Key is "Candidate_ID", this results into two partitions, which will generate issues(e.g. Hot Partition)
	A strategy that allows better distribution of items evently across partitions
	Add a suffix to PArtition Key value 
	Two methods:
		Sharding Using Random Suffix
		Sharding Using Calculated Suffix
=======================================================================================================
DynamoDB - Write Types
	Concurrent Writes  (2 users updating same DB Item)
		User 1 update : value =1
		User 2 update : value =2
		Result - The second write overwrites the first write
	
	Conditional Writes
	        User 1 update : value =1  only if value = 0                                                                                                             
		User 2 update : value =2  only if value = 0
		Result - The forst write is accepted, the second write fails

	Atomic Writes
		User 1 update : Increase value by 1 
		User 2 update : Increase value by 2
		Result - Both writes succeed, the value is increased by 3
	
	Batch Writes
		Write/Update many items at a time
===========================================================================================================
DynamoDB - Large Objects PAttern
	1. Store big Objects into S3, and metadata (with object URL) put into DB
	2. get : get metadata from DB and get Big object by URL
------------------------------------------------------------------------------------------------------------
DynamoDB - Indexing S3 Objects Metadata
	Application ---upload--->S3 ---invoke--->Lambda ---store object's metadata---------> DynamoDB Table
	                                                                                             ^
                                    User ---search By Date ---------------------------->Application -|
					    Total Storage used by a consumer
					    List of ALL objects  with certan attributes
					    Find all objects uploaded within a data range
=============================================================================================================
DynamoDB Operations
	Table CleanUp
		Option1 : scan + Delete Item
			very slow, consumes RCU & WRU, expensive
		Option 2 : Drop Table + Recreate table
			Fast, efficient, cheap
	Copyng a DynamoDB Table
		Option 1 : Using AWS Data Pipeline
		Option 2 : Backup and restore into a new table 
			Takes some time
		Option 3 : Scan + PutItem or BatchWriteItem
			Write your own code

Example of Copy table:
	AWS Data Pipeline ---launches---> Amazon EMR Cluster--reads from Table---writes to--->S3
	Emr Cluster ---reads from---> S3 ---and writes to new Table.
===============================================================================================================
DynamoDB - Security & Other Features
	Security
		VPC Endpoints available to access DynamoDB without using the internet
		Access fully controlled by IAM
		Encryption at rest using AWS KMS and in-transit using SSL/TLS
	Backup and Restore featurees available
		Piont-in-time Recovery (PITR) like RDS
		No performence impact
	Global Tables
		Multi-region, multi-active, fully replicated, high performance
	DynamoDB Local
		Develop and test Apps locally without accessing the DynamoDB web service (without internet)
	AWS Database Migration Service (AWS DMS) can be used to migrate to DynamoDB (from MongoDB, Oracle, MySQL, S3, ...)
----------------------------------------------------------------------------------------------------------------
DynamoDB - Users interact with DynamoDB Dirrectly
	Client App(web/mobile) login to identity Providers:     [Amazon Cognito User Pools] ---app, getting temp creds --> 
								[Google]
								[Facebook]
								[OpenID Connect]
								[SAML]

	Obtain (getting) IAM Role, permissions ----> connect to DynamoDB
-----------------------------------------------------------------------------------------------------------------
DynamoDB Fine-Grained Access Control
	Using  "Web Identity Federation" or "Cognito Identity Pools", each user gets AWS credentials
	You can assign IAM role these Users with a "COndition" to limit their API access to DynamoDB
	Leading Keys - limit row-lavel access for users on the "Primary Key"
	Attributes - limit specific attributes the user can see

Example:
	{
	    "Version": "2020-10-10",
	    "Statement":[
		{
		"Effect":"Allow",
		"Action":[      		
		     "dynamodb:GetItem","dynamodb:BatchGetItem","dynamodb:Query",
		     "dynamodb:PutItem", "dynamodb:UpdateItem", "dynamodb:DeleteItem",
		     "dynamodb:BatchWriteIems"
		],
		"Resource": "arn:aws:dynamodb:us-west-1:123456789012:table/MyTable",
		"Condition":{
		    "ForAllValues:StringEquals":{
			"dynamodb:LoadingKeys": ["${cognito-identity.amazonaws.com:sub}"]
		    }
		}
	      }
	    ]
	}
======================================================================================================================
	

	

	
	
	
			
	

	 	 




		
	



	
		
	
	




















